{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Beng machinehack",
      "provenance": [],
      "authorship_tag": "ABX9TyPDh34ZSq1lJnSDeGVOCp4o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoshanM-18/MachineHack-hackathons/blob/main/Beng_machinehack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OWJJtHL42S-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNDt0VBe5S_e"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hkdNxjj5aO8"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjPHcsXM5768",
        "outputId": "1f85f268-de4a-49f8-da87-ce40d1673cde"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1awSwrSf6r8H"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/data/Train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/data/Test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT6U3Fri7BQi"
      },
      "source": [
        "train.dropna(subset=[\"location\", \"size\"], inplace=True, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L20YijFz7J05"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"-\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"-\")\n",
        "    new_xs = list(map(float, new_x))\n",
        "    new_x_one = new_xs[0]\n",
        "    new_x_two = new_xs[1]\n",
        "    \n",
        "    total_x = (new_x_one + new_x_two)/2\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"-\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"-\")\n",
        "    new_xs = list(map(float, new_x))\n",
        "    new_x_one = new_xs[0]\n",
        "    new_x_two = new_xs[1]\n",
        "    \n",
        "    total_x = (new_x_one + new_x_two)/2\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl8MwPQA7NHy"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Guntha\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"G\")\n",
        "    new_x_one = int(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 1089\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Guntha\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"G\")\n",
        "    new_x_one = int(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 1089\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoTgSopd7PNl"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Cents\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"C\")\n",
        "    new_x_one = int(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 435.6\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Cents\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"C\")\n",
        "    new_x_one = int(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 435.6\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pB9G-Tn7ReK"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Acres\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"A\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 43560\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Acres\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"A\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 43560\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfHbyVNP7TgX"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Sq. Meter\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"S\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 10.764\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "\n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Sq. Meter\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"S\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 10.764\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkkSTEFP7VRR"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Sq. Yards\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"S\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 9\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Sq. Yards\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"S\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 9\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihvCLtDm7XhL"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Perch\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"P\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 272.25\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Perch\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"P\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 272.25\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QdbRnJy7ZZv"
      },
      "source": [
        "for x in train[train[\"total_sqft\"].astype(str).str.contains(\"Grounds\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = train.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"G\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 2400\n",
        "    \n",
        "    train.loc[x, \"total_sqft\"] = total_x\n",
        "    \n",
        "    \n",
        "for x in test[test[\"total_sqft\"].astype(str).str.contains(\"Grounds\")][\"total_sqft\"].index.tolist():\n",
        "    \n",
        "    xs = test.loc[x, \"total_sqft\"]\n",
        "    new_x = xs.split(\"G\")\n",
        "    new_x_one = float(new_x[0])\n",
        "    \n",
        "    total_x = new_x_one * 2400\n",
        "    \n",
        "    test.loc[x, \"total_sqft\"] = total_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ILzTdDel-LYm",
        "outputId": "eb70e839-ef24-4624-c401-0252682841bd"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area_type</th>\n",
              "      <th>availability</th>\n",
              "      <th>location</th>\n",
              "      <th>size</th>\n",
              "      <th>society</th>\n",
              "      <th>total_sqft</th>\n",
              "      <th>bath</th>\n",
              "      <th>balcony</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>19-Dec</td>\n",
              "      <td>Electronic City Phase II</td>\n",
              "      <td>2 BHK</td>\n",
              "      <td>Coomee</td>\n",
              "      <td>1056</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>39.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Plot  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Chikka Tirupathi</td>\n",
              "      <td>4 Bedroom</td>\n",
              "      <td>Theanmp</td>\n",
              "      <td>2600</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>120.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Uttarahalli</td>\n",
              "      <td>3 BHK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1440</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>62.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Lingadheeranahalli</td>\n",
              "      <td>3 BHK</td>\n",
              "      <td>Soiewre</td>\n",
              "      <td>1521</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Kothanur</td>\n",
              "      <td>2 BHK</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1200</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              area_type   availability  ... balcony   price\n",
              "0  Super built-up  Area         19-Dec  ...     1.0   39.07\n",
              "1            Plot  Area  Ready To Move  ...     3.0  120.00\n",
              "2        Built-up  Area  Ready To Move  ...     3.0   62.00\n",
              "3  Super built-up  Area  Ready To Move  ...     1.0   95.00\n",
              "4  Super built-up  Area  Ready To Move  ...     1.0   51.00\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itc5r4qV-QhL"
      },
      "source": [
        "mean = np.round(np.mean(train[\"balcony\"]))\n",
        "train[\"balcony\"].fillna(mean, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYZx-m6d-aC6"
      },
      "source": [
        "mean_bath = np.round(train[\"bath\"].mean())\n",
        "train[\"bath\"].fillna(mean_bath, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKHpeftS-yPO"
      },
      "source": [
        "train[\"size\"] = train[\"size\"].apply(lambda x: x.strip(\" \")[0])\n",
        "train[\"size\"] = pd.to_numeric(train[\"size\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yj01_vu6_-ca",
        "outputId": "7c82f5f9-2020-4028-cad2-cf9f352c6297"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area_type</th>\n",
              "      <th>availability</th>\n",
              "      <th>location</th>\n",
              "      <th>size</th>\n",
              "      <th>society</th>\n",
              "      <th>total_sqft</th>\n",
              "      <th>bath</th>\n",
              "      <th>balcony</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>19-Dec</td>\n",
              "      <td>Electronic City Phase II</td>\n",
              "      <td>2</td>\n",
              "      <td>Coomee</td>\n",
              "      <td>1056</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>39.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Plot  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Chikka Tirupathi</td>\n",
              "      <td>4</td>\n",
              "      <td>Theanmp</td>\n",
              "      <td>2600</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>120.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Uttarahalli</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1440</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>62.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Lingadheeranahalli</td>\n",
              "      <td>3</td>\n",
              "      <td>Soiewre</td>\n",
              "      <td>1521</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Kothanur</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1200</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              area_type   availability  ... balcony   price\n",
              "0  Super built-up  Area         19-Dec  ...     1.0   39.07\n",
              "1            Plot  Area  Ready To Move  ...     3.0  120.00\n",
              "2        Built-up  Area  Ready To Move  ...     3.0   62.00\n",
              "3  Super built-up  Area  Ready To Move  ...     1.0   95.00\n",
              "4  Super built-up  Area  Ready To Move  ...     1.0   51.00\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YfmDE_oAARY"
      },
      "source": [
        "train[\"total_sqft\"] = pd.to_numeric(train[\"total_sqft\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hj1b5A7ASP3"
      },
      "source": [
        "train.drop(\"society\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8PQrThdAgXC",
        "outputId": "89978e76-7036-403a-e713-82640cb736ef"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13303 entries, 0 to 13319\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   area_type     13303 non-null  object \n",
            " 1   availability  13303 non-null  object \n",
            " 2   location      13303 non-null  object \n",
            " 3   size          13303 non-null  int64  \n",
            " 4   total_sqft    13303 non-null  float64\n",
            " 5   bath          13303 non-null  float64\n",
            " 6   balcony       13303 non-null  float64\n",
            " 7   price         13303 non-null  float64\n",
            "dtypes: float64(4), int64(1), object(3)\n",
            "memory usage: 1.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WeT6qqdJAjQH",
        "outputId": "ccd80e71-166d-46db-fb1b-97803918f1e1"
      },
      "source": [
        "train[train[\"availability\"]==\"Ready To Move\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area_type</th>\n",
              "      <th>availability</th>\n",
              "      <th>location</th>\n",
              "      <th>size</th>\n",
              "      <th>total_sqft</th>\n",
              "      <th>bath</th>\n",
              "      <th>balcony</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Plot  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Chikka Tirupathi</td>\n",
              "      <td>4</td>\n",
              "      <td>2600.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Uttarahalli</td>\n",
              "      <td>3</td>\n",
              "      <td>1440.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Lingadheeranahalli</td>\n",
              "      <td>3</td>\n",
              "      <td>1521.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Kothanur</td>\n",
              "      <td>2</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Whitefield</td>\n",
              "      <td>2</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13314</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Green Glen Layout</td>\n",
              "      <td>3</td>\n",
              "      <td>1715.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>112.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13315</th>\n",
              "      <td>Built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Whitefield</td>\n",
              "      <td>5</td>\n",
              "      <td>3453.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>231.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13316</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Richards Town</td>\n",
              "      <td>4</td>\n",
              "      <td>3600.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13317</th>\n",
              "      <td>Built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Raja Rajeshwari Nagar</td>\n",
              "      <td>2</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13319</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Ready To Move</td>\n",
              "      <td>Doddathoguru</td>\n",
              "      <td>1</td>\n",
              "      <td>550.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10580 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  area_type   availability  ... balcony  price\n",
              "1                Plot  Area  Ready To Move  ...     3.0  120.0\n",
              "2            Built-up  Area  Ready To Move  ...     3.0   62.0\n",
              "3      Super built-up  Area  Ready To Move  ...     1.0   95.0\n",
              "4      Super built-up  Area  Ready To Move  ...     1.0   51.0\n",
              "5      Super built-up  Area  Ready To Move  ...     1.0   38.0\n",
              "...                     ...            ...  ...     ...    ...\n",
              "13314  Super built-up  Area  Ready To Move  ...     3.0  112.0\n",
              "13315        Built-up  Area  Ready To Move  ...     0.0  231.0\n",
              "13316  Super built-up  Area  Ready To Move  ...     2.0  400.0\n",
              "13317        Built-up  Area  Ready To Move  ...     1.0   60.0\n",
              "13319  Super built-up  Area  Ready To Move  ...     1.0   17.0\n",
              "\n",
              "[10580 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M04dKIu6BBHa",
        "outputId": "a63fd194-0dfd-4544-9627-e0cf0eb11dc8"
      },
      "source": [
        "train[\"availability\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['19-Dec', 'Ready To Move', '18-May', '18-Feb', '18-Nov', '20-Dec',\n",
              "       '17-Oct', '21-Dec', '19-Sep', '20-Sep', '18-Mar', '20-Feb',\n",
              "       '18-Apr', '20-Aug', '18-Oct', '19-Mar', '17-Sep', '18-Dec',\n",
              "       '17-Aug', '19-Apr', '18-Jun', '22-Dec', '22-Jan', '18-Aug',\n",
              "       '19-Jan', '17-Jul', '18-Jul', '21-Jun', '20-May', '19-Aug',\n",
              "       '18-Sep', '17-May', '17-Jun', '21-May', '18-Jan', '20-Mar',\n",
              "       '17-Dec', '16-Mar', '19-Jun', '22-Jun', '19-Jul', '21-Feb',\n",
              "       '19-May', '17-Nov', '20-Oct', '20-Jun', '19-Feb', '21-Oct',\n",
              "       '21-Jan', '17-Mar', '17-Apr', '22-May', '19-Oct', '21-Jul',\n",
              "       '21-Nov', '21-Mar', '16-Dec', '22-Mar', '20-Jan', '21-Sep',\n",
              "       '21-Aug', '14-Nov', '19-Nov', '15-Nov', '16-Jul', '15-Jun',\n",
              "       '17-Feb', '20-Nov', '20-Jul', '16-Sep', '15-Oct', '15-Dec',\n",
              "       '16-Oct', '22-Nov', '15-Aug', '17-Jan', '16-Nov', '20-Apr',\n",
              "       '16-Jan', '14-Jul'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9WB-E9NBJYw",
        "outputId": "b24c48e1-a7d1-4575-ad04-abba1fe4bffa"
      },
      "source": [
        "test[\"availability\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Ready To Move', '18-Apr', '18-Dec', '18-Jul', '19-Dec', '19-Oct',\n",
              "       '17-Dec', '18-May', '22-Jun', '18-Feb', '18-Aug', '18-Jun',\n",
              "       '18-Mar', '20-Dec', '17-Jun', '21-Mar', '17-Jul', '15-Oct',\n",
              "       'Immediate Possession', '19-Sep', '17-Jan', '19-Jun', '21-May',\n",
              "       '22-May', '18-Oct', '18-Sep', '21-Dec', '18-Nov', '17-Nov',\n",
              "       '19-Jan', '17-May', '19-Mar', '17-Sep', '17-Apr', '20-Jul',\n",
              "       '19-Nov', '21-Jan', '21-Feb', '20-Jun', '19-May', '21-Jul',\n",
              "       '20-Jan', '18-Jan', '19-Feb', '19-Aug', '16-Jul', '19-Jul',\n",
              "       '17-Aug', '21-Jun', '16-Apr', '20-Aug'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONMrTS2JCOFu"
      },
      "source": [
        "list_loc = train[\"location\"].unique().tolist()\n",
        "list_loc_test = test[\"location\"].unique().tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb32UnTiCoF4"
      },
      "source": [
        "l1 = []\n",
        "l2 = []\n",
        "\n",
        "for x in list_loc_test:\n",
        "  if x not in list_loc:\n",
        "    l1.append(x)\n",
        "  elif x in list_loc:\n",
        "    l2.append(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogKvzfhaC-ma",
        "outputId": "4e2b75c9-175a-4000-f6ac-699039d9ebc9"
      },
      "source": [
        "len(l1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SNPHvZOC_8D",
        "outputId": "af16c34c-b430-47cf-8a6a-80984204b1bf"
      },
      "source": [
        "len(l2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "442"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBz9iozqDCtx",
        "outputId": "a965870a-0e94-49f8-eed1-295b528ff72e"
      },
      "source": [
        "len(list_loc_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it9xZ8b0Ervw"
      },
      "source": [
        "train.drop(\"availability\", axis=1, inplace=True)\n",
        "test.drop(\"availability\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PKeJQO1Exv2",
        "outputId": "5ae6c33c-37fe-4336-e363-0f88b0493a84"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 13303 entries, 0 to 13319\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   area_type   13303 non-null  object \n",
            " 1   location    13303 non-null  object \n",
            " 2   size        13303 non-null  int64  \n",
            " 3   total_sqft  13303 non-null  float64\n",
            " 4   bath        13303 non-null  float64\n",
            " 5   balcony     13303 non-null  float64\n",
            " 6   price       13303 non-null  float64\n",
            "dtypes: float64(4), int64(1), object(2)\n",
            "memory usage: 1.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYZnFAo3E3le"
      },
      "source": [
        "le1 = LabelEncoder()\n",
        "train[\"location\"] = le1.fit_transform(train[\"location\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-5E6JjaY8Xi"
      },
      "source": [
        "ct = make_column_transformer(\n",
        "    (OneHotEncoder(), [\"area_type\"]),\n",
        "    (MinMaxScaler(), [\"size\", \"total_sqft\", \"bath\", \"balcony\", \"location\"])\n",
        ")\n",
        "\n",
        "X = train.drop(\"price\", axis=1)\n",
        "y = train[\"price\"]\n",
        "\n",
        "ct.fit(X)\n",
        "\n",
        "X_scaled = ct.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L2VtldXZj8W"
      },
      "source": [
        "y = np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOqKvpc9aKQe",
        "outputId": "9bb196d2-5a6b-4e0a-9844-9abd6c60ac4b"
      },
      "source": [
        "X_scaled[0],y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
              "        1.25000000e-01, 8.07316198e-04, 2.56410256e-02, 3.33333333e-01,\n",
              "        3.21565618e-01]),\n",
              " array([ 39.07, 120.  ,  62.  , ...,  60.  , 488.  ,  17.  ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-Eiu_vtWaLPI",
        "outputId": "0695c6d6-937e-45f8-f698-85ce8b8b2d85"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area_type</th>\n",
              "      <th>location</th>\n",
              "      <th>size</th>\n",
              "      <th>society</th>\n",
              "      <th>total_sqft</th>\n",
              "      <th>bath</th>\n",
              "      <th>balcony</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Brookefield</td>\n",
              "      <td>2 BHK</td>\n",
              "      <td>Roeekbl</td>\n",
              "      <td>1225</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Plot  Area</td>\n",
              "      <td>Akshaya Nagar</td>\n",
              "      <td>9 Bedroom</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2400</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Plot  Area</td>\n",
              "      <td>Hennur Road</td>\n",
              "      <td>4 Bedroom</td>\n",
              "      <td>Saandtt</td>\n",
              "      <td>1650</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Kodichikkanahalli</td>\n",
              "      <td>3 BHK</td>\n",
              "      <td>Winerri</td>\n",
              "      <td>1322</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Super built-up  Area</td>\n",
              "      <td>Konanakunte</td>\n",
              "      <td>2 BHK</td>\n",
              "      <td>AmageSa</td>\n",
              "      <td>1161</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              area_type           location       size  ... bath balcony  price\n",
              "0  Super built-up  Area        Brookefield      2 BHK  ...  2.0     2.0    NaN\n",
              "1            Plot  Area      Akshaya Nagar  9 Bedroom  ...  9.0     2.0    NaN\n",
              "2            Plot  Area        Hennur Road  4 Bedroom  ...  5.0     2.0    NaN\n",
              "3  Super built-up  Area  Kodichikkanahalli      3 BHK  ...  3.0     1.0    NaN\n",
              "4  Super built-up  Area        Konanakunte      2 BHK  ...  2.0     1.0    NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkzRhDRUaSHi"
      },
      "source": [
        "test.drop(\"society\", axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrtQl0uTacN-"
      },
      "source": [
        "test.loc[151, \"size\"] = \"4 BHK\"\n",
        "test.loc[1160, \"size\"] = \"5 BHK\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-RTd_MmagC9"
      },
      "source": [
        "test[\"size\"] = test[\"size\"].apply(lambda x: x.strip(\" \")[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEfHpzkhaiz4"
      },
      "source": [
        "test_mean = np.round(test[\"bath\"].mean())\n",
        "test[\"bath\"].fillna(test_mean, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACJlZuW3aqB8"
      },
      "source": [
        "test_mean_bal = np.round(test[\"balcony\"].mean())\n",
        "test[\"balcony\"].fillna(test_mean_bal, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6yNnfrla-Yc"
      },
      "source": [
        "test[\"total_sqft\"] = pd.to_numeric(test[\"total_sqft\"])\n",
        "test[\"size\"] = pd.to_numeric(test[\"size\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmBPqtxXFZv7"
      },
      "source": [
        "le = LabelEncoder()\n",
        "test[\"location\"] = le.fit_transform(test[\"location\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oamjZ6EebAfk",
        "outputId": "359fda7f-6cbc-494d-8c9e-10e465fe0f73"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1480 entries, 0 to 1479\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   area_type   1480 non-null   object \n",
            " 1   location    1480 non-null   int64  \n",
            " 2   size        1480 non-null   int64  \n",
            " 3   total_sqft  1480 non-null   float64\n",
            " 4   bath        1480 non-null   float64\n",
            " 5   balcony     1480 non-null   float64\n",
            " 6   price       0 non-null      float64\n",
            "dtypes: float64(4), int64(2), object(1)\n",
            "memory usage: 81.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj3qATSDbHyH"
      },
      "source": [
        "X_test = test.drop(\"price\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riznyNb2bITm"
      },
      "source": [
        "X_test_scaled = ct.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ic24WzEb-mw",
        "outputId": "4165183a-1b3a-4d85-8c12-4ffbc202c202"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Dense(512, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(32, activation=\"relu\"))\n",
        "\n",
        "model.add(keras.layers.Dropout(0.6))\n",
        "\n",
        "model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
        "\n",
        "model.compile(loss=keras.losses.mae, metrics=[\"mae\"], \n",
        "              optimizer = keras.optimizers.Adam(lr=0.01))\n",
        "\n",
        "model.fit(X_scaled, y, epochs=500, batch_size=150, validation_split=0.10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "80/80 [==============================] - 1s 5ms/step - loss: 71.9826 - mae: 71.9826 - val_loss: 56.0661 - val_mae: 56.0661\n",
            "Epoch 2/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 58.9848 - mae: 58.9848 - val_loss: 54.8409 - val_mae: 54.8409\n",
            "Epoch 3/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 57.6464 - mae: 57.6464 - val_loss: 62.5567 - val_mae: 62.5567\n",
            "Epoch 4/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 57.0086 - mae: 57.0086 - val_loss: 54.5778 - val_mae: 54.5778\n",
            "Epoch 5/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 54.5600 - mae: 54.5600 - val_loss: 53.9353 - val_mae: 53.9353\n",
            "Epoch 6/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 54.1008 - mae: 54.1008 - val_loss: 52.3524 - val_mae: 52.3524\n",
            "Epoch 7/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 54.5227 - mae: 54.5227 - val_loss: 53.9405 - val_mae: 53.9405\n",
            "Epoch 8/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 57.1239 - mae: 57.1239 - val_loss: 55.8461 - val_mae: 55.8461\n",
            "Epoch 9/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 54.5752 - mae: 54.5752 - val_loss: 53.5780 - val_mae: 53.5780\n",
            "Epoch 10/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 55.3546 - mae: 55.3546 - val_loss: 52.0701 - val_mae: 52.0701\n",
            "Epoch 11/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 55.5902 - mae: 55.5902 - val_loss: 52.5998 - val_mae: 52.5998\n",
            "Epoch 12/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.9295 - mae: 52.9295 - val_loss: 54.4633 - val_mae: 54.4633\n",
            "Epoch 13/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.6570 - mae: 53.6570 - val_loss: 54.5157 - val_mae: 54.5157\n",
            "Epoch 14/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 54.4288 - mae: 54.4288 - val_loss: 54.3621 - val_mae: 54.3621\n",
            "Epoch 15/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 55.5821 - mae: 55.5821 - val_loss: 51.5205 - val_mae: 51.5205\n",
            "Epoch 16/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.7269 - mae: 52.7269 - val_loss: 51.4400 - val_mae: 51.4400\n",
            "Epoch 17/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.4759 - mae: 53.4759 - val_loss: 53.0854 - val_mae: 53.0854\n",
            "Epoch 18/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.1340 - mae: 51.1340 - val_loss: 51.2358 - val_mae: 51.2358\n",
            "Epoch 19/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.8433 - mae: 53.8433 - val_loss: 53.5610 - val_mae: 53.5610\n",
            "Epoch 20/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 53.4725 - mae: 53.4725 - val_loss: 52.5538 - val_mae: 52.5538\n",
            "Epoch 21/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.4095 - mae: 53.4095 - val_loss: 52.5316 - val_mae: 52.5316\n",
            "Epoch 22/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.6937 - mae: 52.6937 - val_loss: 51.6810 - val_mae: 51.6810\n",
            "Epoch 23/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 54.7452 - mae: 54.7452 - val_loss: 52.5932 - val_mae: 52.5932\n",
            "Epoch 24/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.6497 - mae: 53.6497 - val_loss: 52.8079 - val_mae: 52.8079\n",
            "Epoch 25/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.6843 - mae: 51.6843 - val_loss: 51.3569 - val_mae: 51.3569\n",
            "Epoch 26/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.9565 - mae: 52.9565 - val_loss: 51.8835 - val_mae: 51.8835\n",
            "Epoch 27/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.2964 - mae: 51.2964 - val_loss: 53.9094 - val_mae: 53.9094\n",
            "Epoch 28/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.3466 - mae: 53.3466 - val_loss: 50.9690 - val_mae: 50.9690\n",
            "Epoch 29/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.2160 - mae: 53.2160 - val_loss: 51.1614 - val_mae: 51.1614\n",
            "Epoch 30/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 53.5102 - mae: 53.5102 - val_loss: 51.2859 - val_mae: 51.2859\n",
            "Epoch 31/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.2106 - mae: 52.2106 - val_loss: 53.5222 - val_mae: 53.5222\n",
            "Epoch 32/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.1998 - mae: 52.1998 - val_loss: 51.5089 - val_mae: 51.5089\n",
            "Epoch 33/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.9092 - mae: 52.9092 - val_loss: 51.0252 - val_mae: 51.0252\n",
            "Epoch 34/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.5096 - mae: 52.5096 - val_loss: 53.3739 - val_mae: 53.3739\n",
            "Epoch 35/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.6600 - mae: 51.6600 - val_loss: 52.2542 - val_mae: 52.2542\n",
            "Epoch 36/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.9156 - mae: 51.9156 - val_loss: 51.2300 - val_mae: 51.2300\n",
            "Epoch 37/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.8233 - mae: 49.8233 - val_loss: 53.8211 - val_mae: 53.8211\n",
            "Epoch 38/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.7581 - mae: 51.7581 - val_loss: 52.9206 - val_mae: 52.9206\n",
            "Epoch 39/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.9474 - mae: 52.9474 - val_loss: 51.4298 - val_mae: 51.4298\n",
            "Epoch 40/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.5186 - mae: 51.5186 - val_loss: 51.2147 - val_mae: 51.2147\n",
            "Epoch 41/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 50.5053 - mae: 50.5053 - val_loss: 50.8942 - val_mae: 50.8942\n",
            "Epoch 42/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.7310 - mae: 48.7310 - val_loss: 51.1593 - val_mae: 51.1593\n",
            "Epoch 43/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.8097 - mae: 51.8097 - val_loss: 50.6162 - val_mae: 50.6162\n",
            "Epoch 44/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.1442 - mae: 49.1442 - val_loss: 50.9364 - val_mae: 50.9364\n",
            "Epoch 45/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 52.2229 - mae: 52.2229 - val_loss: 51.7307 - val_mae: 51.7307\n",
            "Epoch 46/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.2111 - mae: 51.2111 - val_loss: 50.9801 - val_mae: 50.9801\n",
            "Epoch 47/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.2656 - mae: 49.2656 - val_loss: 51.0729 - val_mae: 51.0729\n",
            "Epoch 48/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.4209 - mae: 49.4209 - val_loss: 51.6348 - val_mae: 51.6348\n",
            "Epoch 49/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.2543 - mae: 51.2543 - val_loss: 50.5240 - val_mae: 50.5240\n",
            "Epoch 50/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 50.4749 - mae: 50.4749 - val_loss: 51.3999 - val_mae: 51.3999\n",
            "Epoch 51/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 50.6598 - mae: 50.6598 - val_loss: 51.2652 - val_mae: 51.2652\n",
            "Epoch 52/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 50.7708 - mae: 50.7708 - val_loss: 51.3736 - val_mae: 51.3736\n",
            "Epoch 53/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.3706 - mae: 48.3706 - val_loss: 52.6907 - val_mae: 52.6907\n",
            "Epoch 54/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.3871 - mae: 49.3871 - val_loss: 52.5709 - val_mae: 52.5709\n",
            "Epoch 55/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.2515 - mae: 49.2515 - val_loss: 53.3495 - val_mae: 53.3495\n",
            "Epoch 56/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 50.3116 - mae: 50.3116 - val_loss: 50.8231 - val_mae: 50.8231\n",
            "Epoch 57/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 51.2367 - mae: 51.2367 - val_loss: 50.3879 - val_mae: 50.3879\n",
            "Epoch 58/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.9353 - mae: 48.9353 - val_loss: 50.5263 - val_mae: 50.5263\n",
            "Epoch 59/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.8498 - mae: 49.8498 - val_loss: 51.3935 - val_mae: 51.3935\n",
            "Epoch 60/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.0249 - mae: 49.0249 - val_loss: 51.1125 - val_mae: 51.1125\n",
            "Epoch 61/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 49.7589 - mae: 49.7589 - val_loss: 51.5518 - val_mae: 51.5518\n",
            "Epoch 62/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.4950 - mae: 47.4950 - val_loss: 50.3034 - val_mae: 50.3034\n",
            "Epoch 63/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.3963 - mae: 48.3963 - val_loss: 50.2472 - val_mae: 50.2472\n",
            "Epoch 64/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.7219 - mae: 49.7219 - val_loss: 50.0332 - val_mae: 50.0332\n",
            "Epoch 65/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.6972 - mae: 48.6972 - val_loss: 50.4097 - val_mae: 50.4097\n",
            "Epoch 66/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.5125 - mae: 47.5125 - val_loss: 50.0693 - val_mae: 50.0693\n",
            "Epoch 67/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.2773 - mae: 49.2773 - val_loss: 52.3350 - val_mae: 52.3350\n",
            "Epoch 68/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.2378 - mae: 47.2378 - val_loss: 51.1937 - val_mae: 51.1937\n",
            "Epoch 69/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.8690 - mae: 46.8690 - val_loss: 49.9618 - val_mae: 49.9618\n",
            "Epoch 70/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.0577 - mae: 48.0577 - val_loss: 50.7454 - val_mae: 50.7454\n",
            "Epoch 71/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.6152 - mae: 47.6152 - val_loss: 49.4362 - val_mae: 49.4362\n",
            "Epoch 72/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.9066 - mae: 49.9066 - val_loss: 50.2507 - val_mae: 50.2507\n",
            "Epoch 73/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 50.1154 - mae: 50.1154 - val_loss: 51.0342 - val_mae: 51.0342\n",
            "Epoch 74/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.7309 - mae: 47.7309 - val_loss: 49.6094 - val_mae: 49.6094\n",
            "Epoch 75/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.3946 - mae: 48.3946 - val_loss: 52.6045 - val_mae: 52.6045\n",
            "Epoch 76/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.4018 - mae: 46.4018 - val_loss: 50.7225 - val_mae: 50.7225\n",
            "Epoch 77/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.8419 - mae: 46.8419 - val_loss: 49.9573 - val_mae: 49.9573\n",
            "Epoch 78/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.6008 - mae: 46.6008 - val_loss: 49.8808 - val_mae: 49.8808\n",
            "Epoch 79/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.7623 - mae: 45.7623 - val_loss: 49.5188 - val_mae: 49.5188\n",
            "Epoch 80/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 49.1938 - mae: 49.1938 - val_loss: 51.7257 - val_mae: 51.7257\n",
            "Epoch 81/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 47.4274 - mae: 47.4274 - val_loss: 49.6872 - val_mae: 49.6872\n",
            "Epoch 82/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.3357 - mae: 47.3357 - val_loss: 49.9187 - val_mae: 49.9187\n",
            "Epoch 83/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 47.1166 - mae: 47.1166 - val_loss: 49.6084 - val_mae: 49.6084\n",
            "Epoch 84/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.1611 - mae: 47.1611 - val_loss: 50.3511 - val_mae: 50.3511\n",
            "Epoch 85/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.8862 - mae: 47.8862 - val_loss: 49.4011 - val_mae: 49.4011\n",
            "Epoch 86/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.8018 - mae: 48.8018 - val_loss: 50.1589 - val_mae: 50.1589\n",
            "Epoch 87/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.2779 - mae: 48.2779 - val_loss: 49.1586 - val_mae: 49.1586\n",
            "Epoch 88/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.4400 - mae: 45.4400 - val_loss: 49.4298 - val_mae: 49.4298\n",
            "Epoch 89/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 48.3079 - mae: 48.3079 - val_loss: 49.9924 - val_mae: 49.9924\n",
            "Epoch 90/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.1634 - mae: 46.1634 - val_loss: 50.0266 - val_mae: 50.0266\n",
            "Epoch 91/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.6294 - mae: 47.6294 - val_loss: 50.5031 - val_mae: 50.5031\n",
            "Epoch 92/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.7792 - mae: 47.7792 - val_loss: 49.1195 - val_mae: 49.1195\n",
            "Epoch 93/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.1334 - mae: 46.1334 - val_loss: 49.7484 - val_mae: 49.7484\n",
            "Epoch 94/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.3073 - mae: 47.3073 - val_loss: 49.2526 - val_mae: 49.2526\n",
            "Epoch 95/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.1617 - mae: 45.1617 - val_loss: 47.2601 - val_mae: 47.2601\n",
            "Epoch 96/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 43.9430 - mae: 43.9430 - val_loss: 47.9815 - val_mae: 47.9815\n",
            "Epoch 97/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.6529 - mae: 46.6529 - val_loss: 49.4706 - val_mae: 49.4706\n",
            "Epoch 98/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.3584 - mae: 46.3584 - val_loss: 51.4095 - val_mae: 51.4095\n",
            "Epoch 99/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 47.9985 - mae: 47.9985 - val_loss: 48.3556 - val_mae: 48.3556\n",
            "Epoch 100/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.6871 - mae: 46.6871 - val_loss: 47.8222 - val_mae: 47.8222\n",
            "Epoch 101/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 44.5723 - mae: 44.5723 - val_loss: 46.6633 - val_mae: 46.6633\n",
            "Epoch 102/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.5602 - mae: 46.5602 - val_loss: 47.5005 - val_mae: 47.5005\n",
            "Epoch 103/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.4159 - mae: 45.4159 - val_loss: 48.6116 - val_mae: 48.6116\n",
            "Epoch 104/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.3359 - mae: 45.3359 - val_loss: 46.4199 - val_mae: 46.4199\n",
            "Epoch 105/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.5439 - mae: 45.5439 - val_loss: 47.9043 - val_mae: 47.9043\n",
            "Epoch 106/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.8365 - mae: 46.8365 - val_loss: 45.0691 - val_mae: 45.0691\n",
            "Epoch 107/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.9678 - mae: 45.9678 - val_loss: 47.4003 - val_mae: 47.4003\n",
            "Epoch 108/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 46.3762 - mae: 46.3762 - val_loss: 44.4566 - val_mae: 44.4566\n",
            "Epoch 109/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 44.3323 - mae: 44.3323 - val_loss: 48.2021 - val_mae: 48.2021\n",
            "Epoch 110/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 44.9724 - mae: 44.9724 - val_loss: 45.1380 - val_mae: 45.1380\n",
            "Epoch 111/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 44.3698 - mae: 44.3698 - val_loss: 47.1531 - val_mae: 47.1531\n",
            "Epoch 112/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 45.8131 - mae: 45.8131 - val_loss: 48.9015 - val_mae: 48.9015\n",
            "Epoch 113/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 43.8887 - mae: 43.8887 - val_loss: 45.5577 - val_mae: 45.5577\n",
            "Epoch 114/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.5491 - mae: 41.5491 - val_loss: 44.1866 - val_mae: 44.1866\n",
            "Epoch 115/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.0578 - mae: 41.0578 - val_loss: 42.6964 - val_mae: 42.6964\n",
            "Epoch 116/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 43.5038 - mae: 43.5038 - val_loss: 43.8791 - val_mae: 43.8791\n",
            "Epoch 117/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 42.0261 - mae: 42.0261 - val_loss: 42.6292 - val_mae: 42.6292\n",
            "Epoch 118/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 42.9766 - mae: 42.9766 - val_loss: 43.7416 - val_mae: 43.7416\n",
            "Epoch 119/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.1294 - mae: 41.1294 - val_loss: 44.6317 - val_mae: 44.6317\n",
            "Epoch 120/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.9014 - mae: 41.9014 - val_loss: 44.5297 - val_mae: 44.5297\n",
            "Epoch 121/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.8303 - mae: 41.8303 - val_loss: 44.0637 - val_mae: 44.0637\n",
            "Epoch 122/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.9790 - mae: 41.9790 - val_loss: 44.6530 - val_mae: 44.6530\n",
            "Epoch 123/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.9343 - mae: 40.9343 - val_loss: 43.6883 - val_mae: 43.6883\n",
            "Epoch 124/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.8674 - mae: 41.8674 - val_loss: 42.7847 - val_mae: 42.7847\n",
            "Epoch 125/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.3501 - mae: 41.3501 - val_loss: 43.7131 - val_mae: 43.7131\n",
            "Epoch 126/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 42.1536 - mae: 42.1536 - val_loss: 46.2659 - val_mae: 46.2659\n",
            "Epoch 127/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.8526 - mae: 41.8526 - val_loss: 45.2846 - val_mae: 45.2846\n",
            "Epoch 128/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 42.3100 - mae: 42.3100 - val_loss: 42.6943 - val_mae: 42.6943\n",
            "Epoch 129/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 43.6607 - mae: 43.6607 - val_loss: 41.4330 - val_mae: 41.4330\n",
            "Epoch 130/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.4341 - mae: 40.4341 - val_loss: 41.5294 - val_mae: 41.5294\n",
            "Epoch 131/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 42.4557 - mae: 42.4557 - val_loss: 41.3581 - val_mae: 41.3581\n",
            "Epoch 132/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.4082 - mae: 40.4082 - val_loss: 50.2446 - val_mae: 50.2446\n",
            "Epoch 133/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 42.0051 - mae: 42.0051 - val_loss: 41.4443 - val_mae: 41.4443\n",
            "Epoch 134/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.2158 - mae: 41.2158 - val_loss: 42.0412 - val_mae: 42.0412\n",
            "Epoch 135/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.8037 - mae: 39.8037 - val_loss: 45.5550 - val_mae: 45.5550\n",
            "Epoch 136/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.8833 - mae: 41.8833 - val_loss: 41.6458 - val_mae: 41.6458\n",
            "Epoch 137/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.7806 - mae: 41.7806 - val_loss: 44.2111 - val_mae: 44.2111\n",
            "Epoch 138/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.0856 - mae: 40.0856 - val_loss: 43.1127 - val_mae: 43.1127\n",
            "Epoch 139/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.5987 - mae: 40.5987 - val_loss: 41.7698 - val_mae: 41.7698\n",
            "Epoch 140/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 42.2384 - mae: 42.2384 - val_loss: 42.3233 - val_mae: 42.3233\n",
            "Epoch 141/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.8929 - mae: 39.8929 - val_loss: 43.3946 - val_mae: 43.3946\n",
            "Epoch 142/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.3248 - mae: 41.3248 - val_loss: 41.8042 - val_mae: 41.8042\n",
            "Epoch 143/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5341 - mae: 39.5341 - val_loss: 42.4985 - val_mae: 42.4985\n",
            "Epoch 144/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.5267 - mae: 40.5267 - val_loss: 42.1487 - val_mae: 42.1487\n",
            "Epoch 145/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.5563 - mae: 40.5563 - val_loss: 41.8624 - val_mae: 41.8624\n",
            "Epoch 146/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.2318 - mae: 39.2318 - val_loss: 44.2604 - val_mae: 44.2604\n",
            "Epoch 147/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4067 - mae: 39.4067 - val_loss: 41.2673 - val_mae: 41.2673\n",
            "Epoch 148/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.9199 - mae: 39.9199 - val_loss: 41.3285 - val_mae: 41.3285\n",
            "Epoch 149/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1471 - mae: 38.1471 - val_loss: 45.5298 - val_mae: 45.5298\n",
            "Epoch 150/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5421 - mae: 39.5421 - val_loss: 41.9659 - val_mae: 41.9659\n",
            "Epoch 151/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.4499 - mae: 39.4499 - val_loss: 40.8492 - val_mae: 40.8492\n",
            "Epoch 152/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 41.0339 - mae: 41.0339 - val_loss: 43.1620 - val_mae: 43.1620\n",
            "Epoch 153/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.8728 - mae: 40.8728 - val_loss: 43.8835 - val_mae: 43.8835\n",
            "Epoch 154/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.3914 - mae: 40.3914 - val_loss: 42.9543 - val_mae: 42.9543\n",
            "Epoch 155/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.4206 - mae: 38.4206 - val_loss: 42.4029 - val_mae: 42.4029\n",
            "Epoch 156/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.4641 - mae: 41.4641 - val_loss: 42.4836 - val_mae: 42.4836\n",
            "Epoch 157/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.9058 - mae: 39.9058 - val_loss: 42.1009 - val_mae: 42.1009\n",
            "Epoch 158/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.4004 - mae: 40.4004 - val_loss: 41.6851 - val_mae: 41.6851\n",
            "Epoch 159/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9792 - mae: 38.9792 - val_loss: 41.2978 - val_mae: 41.2978\n",
            "Epoch 160/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.8159 - mae: 39.8159 - val_loss: 41.9094 - val_mae: 41.9094\n",
            "Epoch 161/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9193 - mae: 38.9193 - val_loss: 43.1641 - val_mae: 43.1641\n",
            "Epoch 162/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.7183 - mae: 40.7183 - val_loss: 41.1257 - val_mae: 41.1257\n",
            "Epoch 163/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.5748 - mae: 41.5748 - val_loss: 42.4733 - val_mae: 42.4733\n",
            "Epoch 164/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.5157 - mae: 40.5157 - val_loss: 42.8012 - val_mae: 42.8012\n",
            "Epoch 165/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.0801 - mae: 40.0801 - val_loss: 43.2612 - val_mae: 43.2612\n",
            "Epoch 166/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.2519 - mae: 40.2519 - val_loss: 42.9063 - val_mae: 42.9063\n",
            "Epoch 167/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.7984 - mae: 40.7984 - val_loss: 45.1505 - val_mae: 45.1505\n",
            "Epoch 168/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.1349 - mae: 41.1349 - val_loss: 49.2402 - val_mae: 49.2402\n",
            "Epoch 169/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.3548 - mae: 40.3548 - val_loss: 48.4232 - val_mae: 48.4232\n",
            "Epoch 170/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.4926 - mae: 40.4926 - val_loss: 49.1672 - val_mae: 49.1672\n",
            "Epoch 171/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.7159 - mae: 41.7159 - val_loss: 41.3485 - val_mae: 41.3485\n",
            "Epoch 172/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.6749 - mae: 40.6749 - val_loss: 40.4613 - val_mae: 40.4613\n",
            "Epoch 173/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.1855 - mae: 41.1855 - val_loss: 43.3193 - val_mae: 43.3193\n",
            "Epoch 174/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.5404 - mae: 39.5404 - val_loss: 44.7214 - val_mae: 44.7214\n",
            "Epoch 175/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.4002 - mae: 41.4002 - val_loss: 42.1106 - val_mae: 42.1106\n",
            "Epoch 176/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.3706 - mae: 39.3706 - val_loss: 44.3357 - val_mae: 44.3357\n",
            "Epoch 177/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.8279 - mae: 40.8279 - val_loss: 43.0647 - val_mae: 43.0647\n",
            "Epoch 178/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5268 - mae: 39.5268 - val_loss: 41.0011 - val_mae: 41.0011\n",
            "Epoch 179/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.6189 - mae: 39.6189 - val_loss: 42.2913 - val_mae: 42.2913\n",
            "Epoch 180/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.7516 - mae: 38.7516 - val_loss: 41.3545 - val_mae: 41.3545\n",
            "Epoch 181/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4153 - mae: 39.4153 - val_loss: 41.2909 - val_mae: 41.2909\n",
            "Epoch 182/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.6091 - mae: 38.6091 - val_loss: 43.8211 - val_mae: 43.8211\n",
            "Epoch 183/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.3879 - mae: 39.3879 - val_loss: 41.0345 - val_mae: 41.0345\n",
            "Epoch 184/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1008 - mae: 38.1008 - val_loss: 41.8347 - val_mae: 41.8347\n",
            "Epoch 185/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.7532 - mae: 38.7532 - val_loss: 42.2215 - val_mae: 42.2215\n",
            "Epoch 186/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.8553 - mae: 39.8553 - val_loss: 43.7343 - val_mae: 43.7343\n",
            "Epoch 187/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.7230 - mae: 37.7230 - val_loss: 42.2945 - val_mae: 42.2945\n",
            "Epoch 188/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.5663 - mae: 38.5663 - val_loss: 42.1411 - val_mae: 42.1411\n",
            "Epoch 189/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2053 - mae: 39.2053 - val_loss: 42.7033 - val_mae: 42.7033\n",
            "Epoch 190/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8752 - mae: 37.8752 - val_loss: 43.7553 - val_mae: 43.7553\n",
            "Epoch 191/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.5306 - mae: 37.5306 - val_loss: 42.9365 - val_mae: 42.9365\n",
            "Epoch 192/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8389 - mae: 37.8389 - val_loss: 44.9191 - val_mae: 44.9191\n",
            "Epoch 193/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1278 - mae: 38.1278 - val_loss: 42.1134 - val_mae: 42.1134\n",
            "Epoch 194/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.3740 - mae: 40.3740 - val_loss: 41.4051 - val_mae: 41.4051\n",
            "Epoch 195/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1423 - mae: 39.1423 - val_loss: 43.6308 - val_mae: 43.6308\n",
            "Epoch 196/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2748 - mae: 39.2748 - val_loss: 45.4640 - val_mae: 45.4640\n",
            "Epoch 197/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 41.0638 - mae: 41.0638 - val_loss: 41.2731 - val_mae: 41.2731\n",
            "Epoch 198/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.1747 - mae: 39.1747 - val_loss: 40.5502 - val_mae: 40.5502\n",
            "Epoch 199/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3728 - mae: 38.3728 - val_loss: 41.1775 - val_mae: 41.1775\n",
            "Epoch 200/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.1157 - mae: 40.1157 - val_loss: 40.8701 - val_mae: 40.8701\n",
            "Epoch 201/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.4606 - mae: 38.4606 - val_loss: 42.2629 - val_mae: 42.2629\n",
            "Epoch 202/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.8252 - mae: 39.8252 - val_loss: 41.8391 - val_mae: 41.8391\n",
            "Epoch 203/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 41.9386 - mae: 41.9386 - val_loss: 42.6905 - val_mae: 42.6905\n",
            "Epoch 204/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.5403 - mae: 40.5403 - val_loss: 43.7417 - val_mae: 43.7417\n",
            "Epoch 205/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8140 - mae: 37.8140 - val_loss: 41.3902 - val_mae: 41.3902\n",
            "Epoch 206/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5146 - mae: 39.5146 - val_loss: 41.5120 - val_mae: 41.5120\n",
            "Epoch 207/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.6100 - mae: 39.6100 - val_loss: 43.6263 - val_mae: 43.6263\n",
            "Epoch 208/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4317 - mae: 39.4317 - val_loss: 45.1225 - val_mae: 45.1225\n",
            "Epoch 209/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.5829 - mae: 39.5829 - val_loss: 43.2515 - val_mae: 43.2515\n",
            "Epoch 210/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 41.2954 - mae: 41.2954 - val_loss: 41.4713 - val_mae: 41.4713\n",
            "Epoch 211/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.9038 - mae: 39.9038 - val_loss: 44.1214 - val_mae: 44.1214\n",
            "Epoch 212/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.7054 - mae: 39.7054 - val_loss: 42.5310 - val_mae: 42.5310\n",
            "Epoch 213/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4437 - mae: 39.4437 - val_loss: 43.7537 - val_mae: 43.7537\n",
            "Epoch 214/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5996 - mae: 39.5996 - val_loss: 42.0961 - val_mae: 42.0961\n",
            "Epoch 215/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1872 - mae: 38.1872 - val_loss: 42.4447 - val_mae: 42.4447\n",
            "Epoch 216/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.1919 - mae: 40.1919 - val_loss: 41.0307 - val_mae: 41.0307\n",
            "Epoch 217/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5068 - mae: 39.5068 - val_loss: 41.7971 - val_mae: 41.7971\n",
            "Epoch 218/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.4053 - mae: 37.4053 - val_loss: 41.3230 - val_mae: 41.3230\n",
            "Epoch 219/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2857 - mae: 38.2857 - val_loss: 41.3656 - val_mae: 41.3656\n",
            "Epoch 220/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.3346 - mae: 40.3346 - val_loss: 41.6886 - val_mae: 41.6886\n",
            "Epoch 221/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.6919 - mae: 38.6919 - val_loss: 41.8232 - val_mae: 41.8232\n",
            "Epoch 222/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0793 - mae: 38.0793 - val_loss: 45.7593 - val_mae: 45.7593\n",
            "Epoch 223/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.6411 - mae: 39.6411 - val_loss: 41.1804 - val_mae: 41.1804\n",
            "Epoch 224/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2603 - mae: 38.2603 - val_loss: 41.5089 - val_mae: 41.5089\n",
            "Epoch 225/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9797 - mae: 38.9797 - val_loss: 42.5990 - val_mae: 42.5990\n",
            "Epoch 226/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.1104 - mae: 39.1104 - val_loss: 41.4844 - val_mae: 41.4844\n",
            "Epoch 227/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.3312 - mae: 37.3312 - val_loss: 42.9344 - val_mae: 42.9344\n",
            "Epoch 228/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.9687 - mae: 39.9687 - val_loss: 41.6006 - val_mae: 41.6006\n",
            "Epoch 229/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.5020 - mae: 38.5020 - val_loss: 40.5910 - val_mae: 40.5910\n",
            "Epoch 230/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.7851 - mae: 38.7851 - val_loss: 41.6173 - val_mae: 41.6173\n",
            "Epoch 231/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.0796 - mae: 39.0796 - val_loss: 42.2182 - val_mae: 42.2182\n",
            "Epoch 232/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.3974 - mae: 40.3974 - val_loss: 42.0135 - val_mae: 42.0135\n",
            "Epoch 233/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.9600 - mae: 37.9600 - val_loss: 41.6400 - val_mae: 41.6400\n",
            "Epoch 234/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8772 - mae: 37.8772 - val_loss: 41.5892 - val_mae: 41.5892\n",
            "Epoch 235/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0348 - mae: 38.0348 - val_loss: 43.3258 - val_mae: 43.3258\n",
            "Epoch 236/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.6902 - mae: 39.6902 - val_loss: 42.3824 - val_mae: 42.3824\n",
            "Epoch 237/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2223 - mae: 38.2223 - val_loss: 41.1246 - val_mae: 41.1246\n",
            "Epoch 238/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.3557 - mae: 39.3557 - val_loss: 41.3208 - val_mae: 41.3208\n",
            "Epoch 239/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0676 - mae: 38.0676 - val_loss: 43.8874 - val_mae: 43.8874\n",
            "Epoch 240/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1288 - mae: 38.1288 - val_loss: 41.1456 - val_mae: 41.1456\n",
            "Epoch 241/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2025 - mae: 38.2025 - val_loss: 42.1532 - val_mae: 42.1532\n",
            "Epoch 242/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.6422 - mae: 38.6422 - val_loss: 44.8196 - val_mae: 44.8196\n",
            "Epoch 243/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0590 - mae: 38.0590 - val_loss: 42.3954 - val_mae: 42.3954\n",
            "Epoch 244/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1857 - mae: 38.1857 - val_loss: 41.1630 - val_mae: 41.1630\n",
            "Epoch 245/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4478 - mae: 38.4478 - val_loss: 44.3621 - val_mae: 44.3621\n",
            "Epoch 246/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.8859 - mae: 38.8859 - val_loss: 41.9188 - val_mae: 41.9188\n",
            "Epoch 247/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.6535 - mae: 38.6535 - val_loss: 40.5717 - val_mae: 40.5717\n",
            "Epoch 248/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9874 - mae: 38.9874 - val_loss: 41.7365 - val_mae: 41.7365\n",
            "Epoch 249/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.3750 - mae: 38.3750 - val_loss: 41.7505 - val_mae: 41.7505\n",
            "Epoch 250/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.0774 - mae: 38.0774 - val_loss: 42.6708 - val_mae: 42.6708\n",
            "Epoch 251/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.2250 - mae: 39.2250 - val_loss: 41.7884 - val_mae: 41.7884\n",
            "Epoch 252/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.1039 - mae: 40.1039 - val_loss: 41.0350 - val_mae: 41.0350\n",
            "Epoch 253/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4657 - mae: 38.4657 - val_loss: 40.5279 - val_mae: 40.5279\n",
            "Epoch 254/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5316 - mae: 39.5316 - val_loss: 41.6068 - val_mae: 41.6068\n",
            "Epoch 255/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1625 - mae: 38.1625 - val_loss: 42.5160 - val_mae: 42.5160\n",
            "Epoch 256/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.7493 - mae: 38.7493 - val_loss: 43.6938 - val_mae: 43.6938\n",
            "Epoch 257/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.3862 - mae: 38.3862 - val_loss: 41.1170 - val_mae: 41.1170\n",
            "Epoch 258/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.1592 - mae: 40.1592 - val_loss: 42.2449 - val_mae: 42.2449\n",
            "Epoch 259/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1949 - mae: 38.1949 - val_loss: 43.8888 - val_mae: 43.8888\n",
            "Epoch 260/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.8596 - mae: 38.8596 - val_loss: 41.3503 - val_mae: 41.3503\n",
            "Epoch 261/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.3254 - mae: 39.3254 - val_loss: 40.9236 - val_mae: 40.9236\n",
            "Epoch 262/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1092 - mae: 38.1092 - val_loss: 41.4543 - val_mae: 41.4543\n",
            "Epoch 263/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1232 - mae: 38.1232 - val_loss: 42.1705 - val_mae: 42.1705\n",
            "Epoch 264/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.0742 - mae: 40.0742 - val_loss: 42.5771 - val_mae: 42.5771\n",
            "Epoch 265/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.7786 - mae: 37.7786 - val_loss: 43.2200 - val_mae: 43.2200\n",
            "Epoch 266/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2560 - mae: 38.2560 - val_loss: 40.3806 - val_mae: 40.3806\n",
            "Epoch 267/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.6567 - mae: 39.6567 - val_loss: 41.3034 - val_mae: 41.3034\n",
            "Epoch 268/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.9074 - mae: 39.9074 - val_loss: 44.2749 - val_mae: 44.2749\n",
            "Epoch 269/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2950 - mae: 38.2950 - val_loss: 43.3531 - val_mae: 43.3531\n",
            "Epoch 270/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1034 - mae: 39.1034 - val_loss: 41.7729 - val_mae: 41.7729\n",
            "Epoch 271/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.8098 - mae: 38.8098 - val_loss: 45.2707 - val_mae: 45.2707\n",
            "Epoch 272/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9644 - mae: 38.9644 - val_loss: 42.2755 - val_mae: 42.2755\n",
            "Epoch 273/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1201 - mae: 39.1201 - val_loss: 41.8228 - val_mae: 41.8228\n",
            "Epoch 274/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.1463 - mae: 36.1463 - val_loss: 42.9600 - val_mae: 42.9600\n",
            "Epoch 275/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5077 - mae: 39.5077 - val_loss: 42.3148 - val_mae: 42.3148\n",
            "Epoch 276/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1316 - mae: 39.1316 - val_loss: 43.6099 - val_mae: 43.6099\n",
            "Epoch 277/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.7031 - mae: 38.7031 - val_loss: 41.7312 - val_mae: 41.7312\n",
            "Epoch 278/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.4988 - mae: 38.4988 - val_loss: 43.7557 - val_mae: 43.7557\n",
            "Epoch 279/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4097 - mae: 38.4097 - val_loss: 41.4454 - val_mae: 41.4454\n",
            "Epoch 280/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.6692 - mae: 40.6692 - val_loss: 42.2753 - val_mae: 42.2753\n",
            "Epoch 281/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0666 - mae: 38.0666 - val_loss: 46.3079 - val_mae: 46.3079\n",
            "Epoch 282/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.1863 - mae: 39.1863 - val_loss: 42.1500 - val_mae: 42.1500\n",
            "Epoch 283/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3670 - mae: 38.3670 - val_loss: 43.4549 - val_mae: 43.4549\n",
            "Epoch 284/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.7581 - mae: 38.7581 - val_loss: 41.7356 - val_mae: 41.7356\n",
            "Epoch 285/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2029 - mae: 38.2029 - val_loss: 40.4651 - val_mae: 40.4651\n",
            "Epoch 286/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.5869 - mae: 37.5869 - val_loss: 42.7584 - val_mae: 42.7584\n",
            "Epoch 287/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2959 - mae: 38.2959 - val_loss: 47.6150 - val_mae: 47.6150\n",
            "Epoch 288/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.4156 - mae: 40.4156 - val_loss: 41.7001 - val_mae: 41.7001\n",
            "Epoch 289/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.9249 - mae: 36.9249 - val_loss: 41.3327 - val_mae: 41.3327\n",
            "Epoch 290/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.9918 - mae: 38.9918 - val_loss: 40.7086 - val_mae: 40.7086\n",
            "Epoch 291/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.3621 - mae: 40.3621 - val_loss: 44.1763 - val_mae: 44.1763\n",
            "Epoch 292/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.8582 - mae: 38.8582 - val_loss: 44.9228 - val_mae: 44.9228\n",
            "Epoch 293/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.9601 - mae: 38.9601 - val_loss: 42.1765 - val_mae: 42.1765\n",
            "Epoch 294/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 42.0113 - mae: 42.0113 - val_loss: 42.3359 - val_mae: 42.3359\n",
            "Epoch 295/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2852 - mae: 38.2852 - val_loss: 42.6191 - val_mae: 42.6191\n",
            "Epoch 296/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.9326 - mae: 37.9326 - val_loss: 41.7107 - val_mae: 41.7107\n",
            "Epoch 297/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.7028 - mae: 39.7028 - val_loss: 43.3839 - val_mae: 43.3839\n",
            "Epoch 298/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4428 - mae: 38.4428 - val_loss: 44.1923 - val_mae: 44.1923\n",
            "Epoch 299/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9475 - mae: 38.9475 - val_loss: 43.2299 - val_mae: 43.2299\n",
            "Epoch 300/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.8131 - mae: 38.8131 - val_loss: 42.5913 - val_mae: 42.5913\n",
            "Epoch 301/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.9354 - mae: 39.9354 - val_loss: 40.5141 - val_mae: 40.5141\n",
            "Epoch 302/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.0271 - mae: 38.0271 - val_loss: 40.8923 - val_mae: 40.8923\n",
            "Epoch 303/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.8069 - mae: 36.8069 - val_loss: 42.3565 - val_mae: 42.3565\n",
            "Epoch 304/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.5188 - mae: 36.5188 - val_loss: 41.2828 - val_mae: 41.2828\n",
            "Epoch 305/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.7648 - mae: 37.7648 - val_loss: 40.7373 - val_mae: 40.7373\n",
            "Epoch 306/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.6199 - mae: 36.6199 - val_loss: 43.1144 - val_mae: 43.1144\n",
            "Epoch 307/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.0780 - mae: 37.0780 - val_loss: 40.4689 - val_mae: 40.4689\n",
            "Epoch 308/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.1161 - mae: 38.1161 - val_loss: 42.2743 - val_mae: 42.2743\n",
            "Epoch 309/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.8649 - mae: 37.8649 - val_loss: 41.6869 - val_mae: 41.6869\n",
            "Epoch 310/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.1795 - mae: 37.1795 - val_loss: 41.1278 - val_mae: 41.1278\n",
            "Epoch 311/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4145 - mae: 39.4145 - val_loss: 43.2947 - val_mae: 43.2947\n",
            "Epoch 312/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2059 - mae: 38.2059 - val_loss: 44.0889 - val_mae: 44.0889\n",
            "Epoch 313/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.8163 - mae: 38.8163 - val_loss: 42.5446 - val_mae: 42.5446\n",
            "Epoch 314/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4991 - mae: 39.4991 - val_loss: 41.1648 - val_mae: 41.1648\n",
            "Epoch 315/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.7417 - mae: 37.7417 - val_loss: 44.0980 - val_mae: 44.0980\n",
            "Epoch 316/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.7801 - mae: 38.7801 - val_loss: 43.6417 - val_mae: 43.6417\n",
            "Epoch 317/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3853 - mae: 38.3853 - val_loss: 44.2357 - val_mae: 44.2357\n",
            "Epoch 318/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.5190 - mae: 38.5190 - val_loss: 40.0694 - val_mae: 40.0694\n",
            "Epoch 319/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.7051 - mae: 37.7051 - val_loss: 41.1800 - val_mae: 41.1800\n",
            "Epoch 320/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2968 - mae: 38.2968 - val_loss: 41.7783 - val_mae: 41.7783\n",
            "Epoch 321/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.6096 - mae: 36.6096 - val_loss: 41.0044 - val_mae: 41.0044\n",
            "Epoch 322/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.1732 - mae: 37.1732 - val_loss: 44.2394 - val_mae: 44.2394\n",
            "Epoch 323/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0685 - mae: 38.0685 - val_loss: 45.5683 - val_mae: 45.5683\n",
            "Epoch 324/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.1807 - mae: 38.1807 - val_loss: 40.8616 - val_mae: 40.8616\n",
            "Epoch 325/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.4329 - mae: 37.4329 - val_loss: 40.9455 - val_mae: 40.9455\n",
            "Epoch 326/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.6281 - mae: 38.6281 - val_loss: 43.7652 - val_mae: 43.7652\n",
            "Epoch 327/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5635 - mae: 39.5635 - val_loss: 41.7325 - val_mae: 41.7325\n",
            "Epoch 328/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0586 - mae: 38.0586 - val_loss: 42.5919 - val_mae: 42.5919\n",
            "Epoch 329/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4545 - mae: 39.4545 - val_loss: 41.8424 - val_mae: 41.8424\n",
            "Epoch 330/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.2054 - mae: 40.2054 - val_loss: 42.1068 - val_mae: 42.1068\n",
            "Epoch 331/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3461 - mae: 38.3461 - val_loss: 40.7076 - val_mae: 40.7076\n",
            "Epoch 332/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 40.0518 - mae: 40.0518 - val_loss: 41.4487 - val_mae: 41.4487\n",
            "Epoch 333/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.5120 - mae: 37.5120 - val_loss: 41.4241 - val_mae: 41.4241\n",
            "Epoch 334/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.6083 - mae: 37.6083 - val_loss: 42.3602 - val_mae: 42.3602\n",
            "Epoch 335/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.9071 - mae: 38.9071 - val_loss: 41.1466 - val_mae: 41.1466\n",
            "Epoch 336/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.1715 - mae: 37.1715 - val_loss: 42.5150 - val_mae: 42.5150\n",
            "Epoch 337/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0053 - mae: 38.0053 - val_loss: 40.6223 - val_mae: 40.6223\n",
            "Epoch 338/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.9229 - mae: 36.9229 - val_loss: 43.1392 - val_mae: 43.1392\n",
            "Epoch 339/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1804 - mae: 38.1804 - val_loss: 47.1656 - val_mae: 47.1656\n",
            "Epoch 340/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2386 - mae: 39.2386 - val_loss: 46.4494 - val_mae: 46.4494\n",
            "Epoch 341/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.1993 - mae: 40.1993 - val_loss: 42.1761 - val_mae: 42.1761\n",
            "Epoch 342/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.1027 - mae: 37.1027 - val_loss: 40.3379 - val_mae: 40.3379\n",
            "Epoch 343/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.0837 - mae: 37.0837 - val_loss: 41.2531 - val_mae: 41.2531\n",
            "Epoch 344/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3854 - mae: 38.3854 - val_loss: 40.4327 - val_mae: 40.4327\n",
            "Epoch 345/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.5753 - mae: 38.5753 - val_loss: 40.6613 - val_mae: 40.6613\n",
            "Epoch 346/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.5235 - mae: 38.5235 - val_loss: 40.8733 - val_mae: 40.8733\n",
            "Epoch 347/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.3212 - mae: 39.3212 - val_loss: 40.4253 - val_mae: 40.4253\n",
            "Epoch 348/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.6049 - mae: 38.6049 - val_loss: 42.2514 - val_mae: 42.2514\n",
            "Epoch 349/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.5919 - mae: 36.5919 - val_loss: 43.8041 - val_mae: 43.8041\n",
            "Epoch 350/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.9561 - mae: 37.9561 - val_loss: 42.6042 - val_mae: 42.6042\n",
            "Epoch 351/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.7228 - mae: 38.7228 - val_loss: 44.3052 - val_mae: 44.3052\n",
            "Epoch 352/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.2055 - mae: 38.2055 - val_loss: 42.6179 - val_mae: 42.6179\n",
            "Epoch 353/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.1734 - mae: 38.1734 - val_loss: 40.9083 - val_mae: 40.9083\n",
            "Epoch 354/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.8421 - mae: 36.8421 - val_loss: 43.0073 - val_mae: 43.0073\n",
            "Epoch 355/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.9536 - mae: 37.9536 - val_loss: 40.9069 - val_mae: 40.9069\n",
            "Epoch 356/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.6436 - mae: 37.6436 - val_loss: 40.8988 - val_mae: 40.8988\n",
            "Epoch 357/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4857 - mae: 39.4857 - val_loss: 41.4411 - val_mae: 41.4411\n",
            "Epoch 358/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.4262 - mae: 39.4262 - val_loss: 41.1954 - val_mae: 41.1954\n",
            "Epoch 359/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.4567 - mae: 36.4567 - val_loss: 41.4159 - val_mae: 41.4159\n",
            "Epoch 360/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8959 - mae: 37.8959 - val_loss: 45.4721 - val_mae: 45.4721\n",
            "Epoch 361/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.6368 - mae: 38.6368 - val_loss: 43.5533 - val_mae: 43.5533\n",
            "Epoch 362/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.3980 - mae: 38.3980 - val_loss: 41.9630 - val_mae: 41.9630\n",
            "Epoch 363/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.4529 - mae: 37.4529 - val_loss: 43.5390 - val_mae: 43.5390\n",
            "Epoch 364/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 35.7528 - mae: 35.7528 - val_loss: 40.9979 - val_mae: 40.9979\n",
            "Epoch 365/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.6365 - mae: 37.6365 - val_loss: 41.1693 - val_mae: 41.1693\n",
            "Epoch 366/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3126 - mae: 37.3126 - val_loss: 41.1981 - val_mae: 41.1981\n",
            "Epoch 367/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2822 - mae: 39.2822 - val_loss: 41.7937 - val_mae: 41.7937\n",
            "Epoch 368/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.0506 - mae: 37.0506 - val_loss: 43.1474 - val_mae: 43.1474\n",
            "Epoch 369/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.6732 - mae: 39.6732 - val_loss: 42.8410 - val_mae: 42.8410\n",
            "Epoch 370/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2882 - mae: 38.2882 - val_loss: 40.2073 - val_mae: 40.2073\n",
            "Epoch 371/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0597 - mae: 38.0597 - val_loss: 42.1606 - val_mae: 42.1606\n",
            "Epoch 372/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8466 - mae: 37.8466 - val_loss: 40.1244 - val_mae: 40.1244\n",
            "Epoch 373/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3790 - mae: 37.3790 - val_loss: 40.2459 - val_mae: 40.2459\n",
            "Epoch 374/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1216 - mae: 39.1216 - val_loss: 39.7908 - val_mae: 39.7908\n",
            "Epoch 375/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.3260 - mae: 39.3260 - val_loss: 40.2722 - val_mae: 40.2722\n",
            "Epoch 376/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.6796 - mae: 36.6796 - val_loss: 40.6923 - val_mae: 40.6923\n",
            "Epoch 377/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2835 - mae: 39.2835 - val_loss: 45.7333 - val_mae: 45.7333\n",
            "Epoch 378/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8154 - mae: 37.8154 - val_loss: 40.0144 - val_mae: 40.0144\n",
            "Epoch 379/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.8975 - mae: 36.8975 - val_loss: 41.8446 - val_mae: 41.8446\n",
            "Epoch 380/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.0381 - mae: 38.0381 - val_loss: 50.9731 - val_mae: 50.9731\n",
            "Epoch 381/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 41.5313 - mae: 41.5313 - val_loss: 42.8216 - val_mae: 42.8216\n",
            "Epoch 382/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.7005 - mae: 38.7005 - val_loss: 41.5236 - val_mae: 41.5236\n",
            "Epoch 383/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.7399 - mae: 36.7399 - val_loss: 40.7944 - val_mae: 40.7944\n",
            "Epoch 384/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.2192 - mae: 36.2192 - val_loss: 42.3629 - val_mae: 42.3629\n",
            "Epoch 385/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.6412 - mae: 38.6412 - val_loss: 39.9777 - val_mae: 39.9777\n",
            "Epoch 386/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2453 - mae: 38.2453 - val_loss: 41.2507 - val_mae: 41.2507\n",
            "Epoch 387/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.1149 - mae: 38.1149 - val_loss: 41.1865 - val_mae: 41.1865\n",
            "Epoch 388/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.8216 - mae: 36.8216 - val_loss: 40.6391 - val_mae: 40.6391\n",
            "Epoch 389/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.8171 - mae: 38.8171 - val_loss: 39.2914 - val_mae: 39.2914\n",
            "Epoch 390/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.0868 - mae: 38.0868 - val_loss: 41.8258 - val_mae: 41.8258\n",
            "Epoch 391/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.9246 - mae: 37.9246 - val_loss: 44.2955 - val_mae: 44.2955\n",
            "Epoch 392/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.1722 - mae: 39.1722 - val_loss: 40.2836 - val_mae: 40.2836\n",
            "Epoch 393/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1693 - mae: 39.1693 - val_loss: 40.0848 - val_mae: 40.0848\n",
            "Epoch 394/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.5800 - mae: 38.5800 - val_loss: 42.6402 - val_mae: 42.6402\n",
            "Epoch 395/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2034 - mae: 38.2034 - val_loss: 40.9075 - val_mae: 40.9075\n",
            "Epoch 396/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.7900 - mae: 37.7900 - val_loss: 43.5495 - val_mae: 43.5495\n",
            "Epoch 397/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.0510 - mae: 39.0510 - val_loss: 42.3855 - val_mae: 42.3855\n",
            "Epoch 398/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.5363 - mae: 37.5363 - val_loss: 44.1571 - val_mae: 44.1571\n",
            "Epoch 399/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.5074 - mae: 39.5074 - val_loss: 40.2086 - val_mae: 40.2086\n",
            "Epoch 400/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.9312 - mae: 39.9312 - val_loss: 42.7134 - val_mae: 42.7134\n",
            "Epoch 401/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.4143 - mae: 39.4143 - val_loss: 40.9823 - val_mae: 40.9823\n",
            "Epoch 402/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.4715 - mae: 37.4715 - val_loss: 41.0055 - val_mae: 41.0055\n",
            "Epoch 403/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.9202 - mae: 36.9202 - val_loss: 41.2419 - val_mae: 41.2419\n",
            "Epoch 404/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.4086 - mae: 37.4086 - val_loss: 40.3817 - val_mae: 40.3817\n",
            "Epoch 405/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 39.1257 - mae: 39.1257 - val_loss: 42.5526 - val_mae: 42.5526\n",
            "Epoch 406/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8290 - mae: 37.8290 - val_loss: 40.8361 - val_mae: 40.8361\n",
            "Epoch 407/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.0573 - mae: 37.0573 - val_loss: 45.2987 - val_mae: 45.2987\n",
            "Epoch 408/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.7537 - mae: 37.7537 - val_loss: 39.8967 - val_mae: 39.8967\n",
            "Epoch 409/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.0702 - mae: 38.0702 - val_loss: 40.8783 - val_mae: 40.8783\n",
            "Epoch 410/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.6376 - mae: 37.6376 - val_loss: 43.4524 - val_mae: 43.4524\n",
            "Epoch 411/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.9622 - mae: 39.9622 - val_loss: 40.7319 - val_mae: 40.7319\n",
            "Epoch 412/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.4242 - mae: 39.4242 - val_loss: 40.7334 - val_mae: 40.7334\n",
            "Epoch 413/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.5988 - mae: 38.5988 - val_loss: 39.3874 - val_mae: 39.3874\n",
            "Epoch 414/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.5555 - mae: 36.5555 - val_loss: 39.1307 - val_mae: 39.1307\n",
            "Epoch 415/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.3026 - mae: 36.3026 - val_loss: 39.5657 - val_mae: 39.5657\n",
            "Epoch 416/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.6603 - mae: 36.6603 - val_loss: 41.4059 - val_mae: 41.4059\n",
            "Epoch 417/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.9190 - mae: 37.9190 - val_loss: 38.6413 - val_mae: 38.6413\n",
            "Epoch 418/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.5831 - mae: 40.5831 - val_loss: 42.2990 - val_mae: 42.2990\n",
            "Epoch 419/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.4377 - mae: 37.4377 - val_loss: 42.0921 - val_mae: 42.0921\n",
            "Epoch 420/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.2667 - mae: 37.2667 - val_loss: 39.8812 - val_mae: 39.8812\n",
            "Epoch 421/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.4079 - mae: 38.4079 - val_loss: 40.0376 - val_mae: 40.0376\n",
            "Epoch 422/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.3402 - mae: 36.3402 - val_loss: 40.9524 - val_mae: 40.9524\n",
            "Epoch 423/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.4450 - mae: 37.4450 - val_loss: 39.8443 - val_mae: 39.8443\n",
            "Epoch 424/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.5220 - mae: 37.5220 - val_loss: 40.3460 - val_mae: 40.3460\n",
            "Epoch 425/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.8699 - mae: 37.8699 - val_loss: 47.4126 - val_mae: 47.4126\n",
            "Epoch 426/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.1494 - mae: 40.1494 - val_loss: 41.1634 - val_mae: 41.1634\n",
            "Epoch 427/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.0729 - mae: 37.0729 - val_loss: 40.2211 - val_mae: 40.2211\n",
            "Epoch 428/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.7443 - mae: 37.7443 - val_loss: 41.7360 - val_mae: 41.7360\n",
            "Epoch 429/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.8259 - mae: 37.8259 - val_loss: 39.6394 - val_mae: 39.6394\n",
            "Epoch 430/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3800 - mae: 37.3800 - val_loss: 41.0874 - val_mae: 41.0874\n",
            "Epoch 431/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2332 - mae: 38.2332 - val_loss: 40.2697 - val_mae: 40.2697\n",
            "Epoch 432/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.5339 - mae: 37.5339 - val_loss: 42.4634 - val_mae: 42.4634\n",
            "Epoch 433/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.1550 - mae: 37.1550 - val_loss: 41.5323 - val_mae: 41.5323\n",
            "Epoch 434/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2277 - mae: 39.2277 - val_loss: 40.7930 - val_mae: 40.7930\n",
            "Epoch 435/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4686 - mae: 38.4686 - val_loss: 42.3209 - val_mae: 42.3209\n",
            "Epoch 436/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.1365 - mae: 38.1365 - val_loss: 40.9710 - val_mae: 40.9710\n",
            "Epoch 437/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.6133 - mae: 38.6133 - val_loss: 40.4589 - val_mae: 40.4589\n",
            "Epoch 438/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.5696 - mae: 37.5696 - val_loss: 39.7529 - val_mae: 39.7529\n",
            "Epoch 439/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.0217 - mae: 37.0217 - val_loss: 40.2845 - val_mae: 40.2845\n",
            "Epoch 440/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.4459 - mae: 36.4459 - val_loss: 41.1050 - val_mae: 41.1050\n",
            "Epoch 441/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.8787 - mae: 39.8787 - val_loss: 40.2707 - val_mae: 40.2707\n",
            "Epoch 442/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.5254 - mae: 36.5254 - val_loss: 40.8843 - val_mae: 40.8843\n",
            "Epoch 443/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.8663 - mae: 37.8663 - val_loss: 41.5560 - val_mae: 41.5560\n",
            "Epoch 444/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.2418 - mae: 38.2418 - val_loss: 41.2267 - val_mae: 41.2267\n",
            "Epoch 445/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.6596 - mae: 36.6596 - val_loss: 40.4921 - val_mae: 40.4921\n",
            "Epoch 446/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 35.6873 - mae: 35.6873 - val_loss: 40.8679 - val_mae: 40.8679\n",
            "Epoch 447/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 36.3223 - mae: 36.3223 - val_loss: 42.7375 - val_mae: 42.7375\n",
            "Epoch 448/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3856 - mae: 37.3856 - val_loss: 42.4498 - val_mae: 42.4498\n",
            "Epoch 449/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.5329 - mae: 37.5329 - val_loss: 41.9747 - val_mae: 41.9747\n",
            "Epoch 450/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.9589 - mae: 37.9589 - val_loss: 40.9718 - val_mae: 40.9718\n",
            "Epoch 451/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.3638 - mae: 37.3638 - val_loss: 41.1765 - val_mae: 41.1765\n",
            "Epoch 452/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 40.5860 - mae: 40.5860 - val_loss: 41.8783 - val_mae: 41.8783\n",
            "Epoch 453/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 35.4495 - mae: 35.4495 - val_loss: 44.5801 - val_mae: 44.5801\n",
            "Epoch 454/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4569 - mae: 38.4569 - val_loss: 41.7022 - val_mae: 41.7022\n",
            "Epoch 455/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3748 - mae: 37.3748 - val_loss: 46.2668 - val_mae: 46.2668\n",
            "Epoch 456/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.4914 - mae: 38.4914 - val_loss: 41.4477 - val_mae: 41.4477\n",
            "Epoch 457/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.4310 - mae: 37.4310 - val_loss: 41.2138 - val_mae: 41.2138\n",
            "Epoch 458/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.1592 - mae: 38.1592 - val_loss: 40.8026 - val_mae: 40.8026\n",
            "Epoch 459/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.6136 - mae: 37.6136 - val_loss: 41.4557 - val_mae: 41.4557\n",
            "Epoch 460/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.5216 - mae: 37.5216 - val_loss: 40.5267 - val_mae: 40.5267\n",
            "Epoch 461/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3661 - mae: 37.3661 - val_loss: 41.4898 - val_mae: 41.4898\n",
            "Epoch 462/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.8943 - mae: 37.8943 - val_loss: 40.0326 - val_mae: 40.0326\n",
            "Epoch 463/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.8851 - mae: 37.8851 - val_loss: 40.4367 - val_mae: 40.4367\n",
            "Epoch 464/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.4701 - mae: 36.4701 - val_loss: 44.7952 - val_mae: 44.7952\n",
            "Epoch 465/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.0931 - mae: 37.0931 - val_loss: 45.1695 - val_mae: 45.1695\n",
            "Epoch 466/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.4647 - mae: 39.4647 - val_loss: 42.9333 - val_mae: 42.9333\n",
            "Epoch 467/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.6095 - mae: 37.6095 - val_loss: 41.0685 - val_mae: 41.0685\n",
            "Epoch 468/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3596 - mae: 37.3596 - val_loss: 41.3032 - val_mae: 41.3032\n",
            "Epoch 469/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3952 - mae: 37.3952 - val_loss: 42.1589 - val_mae: 42.1589\n",
            "Epoch 470/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.2298 - mae: 36.2298 - val_loss: 40.6673 - val_mae: 40.6673\n",
            "Epoch 471/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 38.0243 - mae: 38.0243 - val_loss: 42.4863 - val_mae: 42.4863\n",
            "Epoch 472/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3818 - mae: 38.3818 - val_loss: 42.7233 - val_mae: 42.7233\n",
            "Epoch 473/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.4914 - mae: 37.4914 - val_loss: 42.3089 - val_mae: 42.3089\n",
            "Epoch 474/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 35.1154 - mae: 35.1154 - val_loss: 39.2304 - val_mae: 39.2304\n",
            "Epoch 475/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3767 - mae: 38.3767 - val_loss: 42.6899 - val_mae: 42.6899\n",
            "Epoch 476/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.9960 - mae: 36.9960 - val_loss: 40.2637 - val_mae: 40.2637\n",
            "Epoch 477/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.9705 - mae: 36.9705 - val_loss: 42.9214 - val_mae: 42.9214\n",
            "Epoch 478/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.9371 - mae: 36.9371 - val_loss: 42.2168 - val_mae: 42.2168\n",
            "Epoch 479/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.3549 - mae: 36.3549 - val_loss: 41.2761 - val_mae: 41.2761\n",
            "Epoch 480/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.7022 - mae: 37.7022 - val_loss: 40.5853 - val_mae: 40.5853\n",
            "Epoch 481/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.7557 - mae: 37.7557 - val_loss: 42.2383 - val_mae: 42.2383\n",
            "Epoch 482/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 39.2152 - mae: 39.2152 - val_loss: 44.3714 - val_mae: 44.3714\n",
            "Epoch 483/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.5181 - mae: 36.5181 - val_loss: 41.7679 - val_mae: 41.7679\n",
            "Epoch 484/500\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 37.1221 - mae: 37.1221 - val_loss: 42.8517 - val_mae: 42.8517\n",
            "Epoch 485/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.7295 - mae: 38.7295 - val_loss: 40.4701 - val_mae: 40.4701\n",
            "Epoch 486/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.5919 - mae: 36.5919 - val_loss: 42.5177 - val_mae: 42.5177\n",
            "Epoch 487/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.1014 - mae: 36.1014 - val_loss: 40.2276 - val_mae: 40.2276\n",
            "Epoch 488/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 35.3899 - mae: 35.3899 - val_loss: 41.4036 - val_mae: 41.4036\n",
            "Epoch 489/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.5495 - mae: 36.5495 - val_loss: 41.5276 - val_mae: 41.5276\n",
            "Epoch 490/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.3078 - mae: 37.3078 - val_loss: 41.3789 - val_mae: 41.3789\n",
            "Epoch 491/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.8510 - mae: 37.8510 - val_loss: 42.0956 - val_mae: 42.0956\n",
            "Epoch 492/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.1268 - mae: 37.1268 - val_loss: 44.1893 - val_mae: 44.1893\n",
            "Epoch 493/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.9595 - mae: 37.9595 - val_loss: 45.0488 - val_mae: 45.0488\n",
            "Epoch 494/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.8978 - mae: 36.8978 - val_loss: 39.8984 - val_mae: 39.8984\n",
            "Epoch 495/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.1269 - mae: 37.1269 - val_loss: 40.3045 - val_mae: 40.3045\n",
            "Epoch 496/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 38.3667 - mae: 38.3667 - val_loss: 42.4095 - val_mae: 42.4095\n",
            "Epoch 497/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.6121 - mae: 37.6121 - val_loss: 41.0846 - val_mae: 41.0846\n",
            "Epoch 498/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.8744 - mae: 36.8744 - val_loss: 42.2490 - val_mae: 42.2490\n",
            "Epoch 499/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 36.7937 - mae: 36.7937 - val_loss: 40.2821 - val_mae: 40.2821\n",
            "Epoch 500/500\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 37.9203 - mae: 37.9203 - val_loss: 43.0280 - val_mae: 43.0280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2f2d5cf2d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQeftYYMcDe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de10908-63bf-47f5-c816-fd2de983146c"
      },
      "source": [
        "preds = model.predict([X_test_scaled])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 9) dtype=float32>,)\n",
            "Consider rewriting this model with the Functional API.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dta8rNmxcLjF",
        "outputId": "b26a5b32-5785-4773-bc95-17696afe40d3"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 51.255272],\n",
              "       [246.3342  ],\n",
              "       [166.16072 ],\n",
              "       ...,\n",
              "       [ 51.198433],\n",
              "       [ 49.864166],\n",
              "       [ 74.017494]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cpuDqaJFcL9p",
        "outputId": "d8e77a26-f664-4b19-a41f-4900bd15a53e"
      },
      "source": [
        "df = pd.DataFrame(preds)\n",
        "df.columns = [\"price\"]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.255272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246.334198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>166.160721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67.051834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51.230274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1475</th>\n",
              "      <td>52.557537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1476</th>\n",
              "      <td>83.554222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1477</th>\n",
              "      <td>51.198433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>49.864166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1479</th>\n",
              "      <td>74.017494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1480 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           price\n",
              "0      51.255272\n",
              "1     246.334198\n",
              "2     166.160721\n",
              "3      67.051834\n",
              "4      51.230274\n",
              "...          ...\n",
              "1475   52.557537\n",
              "1476   83.554222\n",
              "1477   51.198433\n",
              "1478   49.864166\n",
              "1479   74.017494\n",
              "\n",
              "[1480 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUpf8FEzdmht"
      },
      "source": [
        "df.to_csv(\"/content/test14.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3euEVFcedqAc",
        "outputId": "cd553a21-0bb1-4817-d6ac-7e40f3b84718"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/test14.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_7340adfb-e7c8-41c7-9093-1b2dbb7f0652\", \"test14.csv\", 20486)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbe45QkQeq51"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}